{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots to do, so we're gonna start with some basic pre-processing<br>\n",
    "I'm not sure what else we need at this time other than tokenizing the tags you've generated<br>\n",
    "I'll also take a look at how BERT might help us out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# ^^ hugging face library for word embeddings\n",
    "import sqlite3\n",
    "import re\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "from keybert import KeyBERT\n",
    "\n",
    "# print(\"howdy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so now I pull data from database<br>\n",
    "I definitely remember how to do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for splitting camel case\n",
    "# https://www.geeksforgeeks.org/python-split-camelcase-string-to-individual-strings/\n",
    "\n",
    "def camel_case_split(str):\n",
    "    return re.sub(r'([a-z])([A-Z])',\n",
    "                      r'\\1 \\2', str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  user_id trade_status  \\\n",
      "0   1        1         None   \n",
      "1   2        1         None   \n",
      "2   3        2         None   \n",
      "3   4        2         None   \n",
      "4   5        2         None   \n",
      "\n",
      "                                                tags  \\\n",
      "0     mangaAnimeMerch, diyTools, mechanicalKeyboards   \n",
      "1  collectiblePins, petSittingDogWalking, vintage...   \n",
      "2                             customToys, bakedGoods   \n",
      "3     clayModelingKits, codingLessons, tattooDesigns   \n",
      "4                 leatherGoods, bikeRepairs, watches   \n",
      "\n",
      "                                                text  \\\n",
      "0  Really describe particularly whose opportunity...   \n",
      "1  Analysis father board everybody. Car begin evi...   \n",
      "2  Per assume community dog happy really stop. Ch...   \n",
      "3  By song new know. Particularly third all inves...   \n",
      "4  Three writer policy building. Offer the capita...   \n",
      "\n",
      "                                            new_tags  \n",
      "0  manga Anime Merch, diy Tools, mechanical Keybo...  \n",
      "1  collectible Pins, pet Sitting Dog Walking, vin...  \n",
      "2                           custom Toys, baked Goods  \n",
      "3  clay Modeling Kits, coding Lessons, tattoo Des...  \n",
      "4               leather Goods, bike Repairs, watches  \n"
     ]
    }
   ],
   "source": [
    "# Connecting to Database\n",
    "# If you're Ace\n",
    "con = sqlite3.connect(\"/home/acequantum/playtime/dummy_data/1_dummy_data.db\")\n",
    "# If you're Sean\n",
    "# con = sqlite3.connect(\"C:/Users/seana/OneDrive/Documents/Learning_Playground/Time_data.db\")\n",
    "\n",
    "# cur = con.cursor()\n",
    "\n",
    "# for row in cur.execute('SELECT * FROM posts LIMIT 3;'):\n",
    "    # print(row)\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM posts;\", con)\n",
    "\n",
    "# print(df.head())\n",
    "\n",
    "df['new_tags'] = df['tags']\n",
    "\n",
    "df['new_tags'] = df['tags'].apply(camel_case_split)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# closing connection\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm at a toss up if I want to do a small bit of EDA and then use BERT to get us some more tags or if the deliminated data is enough to go forward with full EDA. I'll lyk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tags:\n",
      " ['manga Anime Merch' 'diy Tools' 'mechanical Keyboards' 'collectible Pins'\n",
      " 'pet Sitting Dog Walking' 'vintage Clothing' 'custom Toys' 'baked Goods'\n",
      " 'clay Modeling Kits' 'coding Lessons' 'tattoo Designs' 'leather Goods'\n",
      " 'bike Repairs' 'watches' 'custom Stickers' 'exotic Spices'\n",
      " 'graphic Design' 'gaming Consoles' 'vintage Vinyl Records'\n",
      " 'gourmet Food Items' 'tailoring' 'art Prints Posters' 'graphic Novels'\n",
      " 'handmade Soap' 'headphones' 'online Courses' 'rare Manuscripts'\n",
      " 'artisanal Cheese' 'designer Handbags' 'camping Gear' 'books'\n",
      " 'blu Rays Dvds' 'skateboards' 'embroidery Kits' 'antique Jewelry'\n",
      " 'handyman Repairs' 'laptops' 'smartwatches' 'houseplants' 'web Design'\n",
      " 'horror Memorabilia' 'fitness Trackers' 'candles Incense' 'surfboards'\n",
      " 'tutoring' 'fresh Produce' 'VRHeadsets' 'mechanic Services'\n",
      " 'snowboarding Gear' 'homemade Preserves' 'custom Art' 'computer Parts'\n",
      " 'piano Lessons' 'local Honey' 'drones' 'comic Books' 'retro Toys'\n",
      " 'storage Solutions' 'dslr Cameras Lenses' 'vintage Postcards'\n",
      " 'fashion Accessories' 'custom Clothing' 'coffee Beans' 'sneakers'\n",
      " 'language Tutoring' 'vinyl Players' 'hiking Gear' 'wall Art'\n",
      " 'costume Jewelry' 'trading Cards' 'haircut' 'knitting Supplies'\n",
      " 'scrapbooking Materials' 'fishing Gear' 'antique Furniture'\n",
      " 'vintage Lamps' 'recording Equipment' 'scooter Parts' 'concert Merch'\n",
      " 'musical Instruments' 'sports Equipment' 'power Tools' 'bread'\n",
      " 'perfumes Colognes' 'handmade Jewelry' 'puzzles' 'board Games'\n",
      " 'pottery Classes' 'stamps' 'sunglasses' 'rare Coins Or Currency'\n",
      " 'textbooks' 'paintball Equipment' 'smart Home Devices' 'used Smartphones'\n",
      " 'handmade Rugs' 'woodworking Commissions' 'craft Supplies' 'DNDMaterials'\n",
      " 'video Games' 'autographed Memorabilia' 'art Supplies' 'action Figures'\n",
      " 'rare Board Games' 'bicycles Bike Parts' 'sewing Machines'\n",
      " 'homemade Sweets' 'small Furniture' 'graphic Cards' 'local Art'\n",
      " 'jewelry Making Kits' 'kitchen Appliances' 'photography Services'\n",
      " 'voice Acting' 'home Decor']\n",
      "Number of unique tags: 115\n"
     ]
    }
   ],
   "source": [
    "# Splitting into a list of tags\n",
    "# Because I forget that dataframes can handle lists as a field.\n",
    "df['split_tags'] = df['new_tags'].str.split(', ')\n",
    "\n",
    "# Boom Explosions\n",
    "all_tags = df['split_tags'].explode()\n",
    "\n",
    "unique_tags = all_tags.unique()\n",
    "print(\"Unique tags:\\n\", unique_tags)\n",
    "print(f\"Number of unique tags: {unique_tags.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratio of tags to posts that was just under 1:10, so I'll maybe see about generating a total of 2,000, but first we'll see what the similarities that we have is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-miniLM-L6-v2')\n",
    "tags = unique_tags\n",
    "\n",
    "tag_embeddings = model.encode(tags)\n",
    "\n",
    "# Reduction to human levels of understanding\n",
    "pca = PCA(n_components=2)\n",
    "tag_embeddings_2d = pca.fit_transform(tag_embeddings)\n",
    "\n",
    "# Time to plot it!\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(tag_embeddings_2d[:, 0], tag_embeddings_2d[:, 1], alpha=0.5)\n",
    "\n",
    "for i, tag in enumerate(tags):\n",
    "    plt.Annotation(tag, (tag_embeddings_2d[i, 0], tag_embeddings_2d[i, 1]))\n",
    "\n",
    "plt.title(\"Semantic Similarity of Tags (PCA)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that did not explain much. Maybe a heatmap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity(tag_embeddings)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(similarity_matrix,\n",
    "            xticklabels=tags,\n",
    "            yticklabels=tags,\n",
    "            annot=True, fmt=\".2f\")\n",
    "\n",
    "plt.title(\"Pairwise Cosine Similarity\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This did also not explain much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to take some time to look at subsets.\n",
    "\n",
    "# Looking at the most used tags\n",
    "top_n = 20 #can be more if we want to look at more.\n",
    "top_tags = pd.Series(all_tags).nlargest(top_n)\n",
    "\n",
    "# Random Subset\n",
    "subset_size = 15\n",
    "randon_tags = random.sample(tags, subset_size)\n",
    "\n",
    "# This is where we'd put category-based subsets \n",
    "# but that feels like a stretch\n",
    "\n",
    "\n",
    "# None of this is going to be useful \n",
    "# except for telling us that our tags are in no way clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like we can use some BERT stuff again?\n",
    "def get_similar_tags(seed_tag, tags, embeddings, top_k=5):\n",
    "    seed_idx = tags.index(seed_tag)\n",
    "    seed_embedding = embeddings[seed_idx].reshape(1, -1)\n",
    "    similarities = cosine_similarity(seed_embedding, embeddings)[0]\n",
    "    similar_indices = similarities.argsort()[-top_k-1:-1][::-1]\n",
    "    return [tags[i] for i in similar_indices]\n",
    "\n",
    "similar_to_bread = get_similar_tags(\"bread\", unique_tags.tolist(), tag_embeddings)\n",
    "\n",
    "print(f\"tags like bread:\\n{similar_to_bread}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, uh... we might need more tags with the help of BERT since he seems to think that of the unique 115 tags that we have, books and sneakers are among the closes relation to bread. I think we did fairly decent with baked goods and coffee means though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('anime merch', 0.893), ('manga anime', 0.8072), ('manga', 0.7742), ('merch', 0.6367), ('anime', 0.6184)]\n",
      "[('diy tools', 1.0), ('tools', 0.8123), ('diy', 0.6488)]\n",
      "[('mechanical keyboards', 1.0), ('keyboards', 0.8344), ('mechanical', 0.6108)]\n",
      "[('collectible pins', 1.0), ('pins', 0.7488), ('collectible', 0.5568)]\n",
      "[('dog walking', 0.803), ('pet sitting', 0.7975), ('sitting dog', 0.7381), ('pet', 0.5432), ('dog', 0.4817)]\n",
      "[('vintage clothing', 1.0), ('vintage', 0.7657), ('clothing', 0.7459)]\n",
      "[('custom toys', 1.0), ('toys', 0.811), ('custom', 0.5708)]\n",
      "[('baked goods', 1.0), ('baked', 0.7927), ('goods', 0.5852)]\n",
      "[('clay modeling', 0.8952), ('modeling kits', 0.7136), ('clay', 0.605), ('kits', 0.5509), ('modeling', 0.4384)]\n",
      "[('coding lessons', 1.0), ('coding', 0.8324), ('lessons', 0.6164)]\n",
      "[('tattoo designs', 1.0), ('tattoo', 0.7875), ('designs', 0.6449)]\n",
      "[('leather goods', 1.0), ('leather', 0.8537), ('goods', 0.6259)]\n",
      "[('bike repairs', 1.0), ('repairs', 0.7486), ('bike', 0.5682)]\n",
      "[('watches', 1.0)]\n",
      "[('custom stickers', 1.0), ('stickers', 0.8112), ('custom', 0.5138)]\n",
      "[('exotic spices', 1.0), ('spices', 0.8678), ('exotic', 0.631)]\n",
      "[('graphic design', 1.0), ('design', 0.7008), ('graphic', 0.6619)]\n",
      "[('gaming consoles', 1.0), ('consoles', 0.9327), ('gaming', 0.7071)]\n",
      "[('vinyl records', 0.9081), ('vintage vinyl', 0.8713), ('vinyl', 0.7124), ('records', 0.5975), ('vintage', 0.5135)]\n",
      "[('gourmet food', 0.9239), ('food items', 0.7778), ('gourmet', 0.7514), ('food', 0.5366), ('items', 0.5032)]\n"
     ]
    }
   ],
   "source": [
    "kw_model = KeyBERT()\n",
    "seed_tags = unique_tags.tolist()[:20]\n",
    "\n",
    "full_list_of_tags = []\n",
    "\n",
    "for tag in seed_tags:\n",
    "    keywords = kw_model.extract_keywords(tag, keyphrase_ngram_range=(1,2))\n",
    "    print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well... it's not the best, but it's a bit better I guess?<br>\n",
    "It's good enough to get us to the next step I guess."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

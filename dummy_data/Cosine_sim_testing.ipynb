{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so. We're going to go through all of this again<br>\n",
    "First test, importing libraries<br>\n",
    "Then embedding function<br>\n",
    "Then getting those embeddings<br>\n",
    "We will have to figure a way to send those to the DB<br>\n",
    "but that's ok<br>\n",
    "Then averaging posts user likes<br>\n",
    "And sending those back somehow<br>\n",
    "It sounds so easy broken into those steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import sqlite3\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok for some reason that only took a second.<br>\n",
    "Now we need to get the posts and run the embeddings on them<br>\n",
    "Actually first we need to make a place to put the vectors<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This isn't going to be used for now but we'll include it anyway.\n",
    "def camel_case_split(str):\n",
    "    return re.sub(r'([a-z])([A-Z])',\n",
    "                      r'\\1 \\2', str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok so we don't actually need a place to put the vectors.\n",
    "# Because SQLite doesn't do that\n",
    "# We will need a way to separate tags in the actual post body\n",
    "# But that's a problem for future Ace when they have access to that specific data.\n",
    "\n",
    "def call_for_data(user_id):\n",
    "    con = sqlite3.connect(\"/home/acequantum/playtime/dummy_data/1_dummy_data.db\")\n",
    "\n",
    "    df_all_posts = pd.read_sql_query(\"SELECT * FROM posts;\", con)\n",
    "\n",
    "    liked_posts_query = \\\n",
    "    f\"SELECT posts.tags \\\n",
    "    FROM likes \\\n",
    "    JOIN posts on likes.post_id = posts.id \\\n",
    "    WHERE likes.user_id = {user_id}\"\n",
    "\n",
    "    user_query = f\"SELECT * FROM users WHERE id={user_id}\"\n",
    "\n",
    "    df_liked_posts = pd.read_sql_query(liked_posts_query, con)\n",
    "\n",
    "    df_user = pd.read_sql_query(user_query, con)\n",
    "\n",
    "    return df_all_posts, df_user, df_liked_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all posts:           id  ...                                               text\n",
      "0          1  ...  Really describe particularly whose opportunity...\n",
      "1          2  ...  Analysis father board everybody. Car begin evi...\n",
      "2          3  ...  Per assume community dog happy really stop. Ch...\n",
      "3          4  ...  By song new know. Particularly third all inves...\n",
      "4          5  ...  Three writer policy building. Offer the capita...\n",
      "...      ...  ...                                                ...\n",
      "26259  26260  ...  Up go also hotel one sometimes kitchen. Box va...\n",
      "26260  26261  ...  Push each difficult someone. Star increase usu...\n",
      "26261  26262  ...  Make well each near. Finish in market official...\n",
      "26262  26263  ...  Example ask sort security husband fast and mis...\n",
      "26263  26264  ...  Yes eye weight from when political. Building p...\n",
      "\n",
      "[26264 rows x 5 columns]\n",
      "user info:     id  ...                                               bios\n",
      "0  292  ...  Significant suggest respond ask born. Speak re...\n",
      "\n",
      "[1 rows x 4 columns]\n",
      "user name: 0    Thomas Jordan\n",
      "Name: name, dtype: object\n",
      "user liked posts: <bound method NDFrame.head of                                                 tags\n",
      "0         mangaAnimeMerch, webDesign, sewingMachines\n",
      "1                       clayModelingKits, localHoney\n",
      "2                                    rareManuscripts\n",
      "3         embroideryKits, freshProduce, pianoLessons\n",
      "4                   vintagePostcards, antiqueJewelry\n",
      "5                 antiqueJewelry, musicalInstruments\n",
      "6                                       handmadeRugs\n",
      "7                                  bicyclesBikeParts\n",
      "8             rareBoardGames, bikeRepairs, homeDecor\n",
      "9                                    fitnessTrackers\n",
      "10                       tattooDesigns, handmadeRugs\n",
      "11                               mechanicalKeyboards\n",
      "12                                   handmadeJewelry\n",
      "13                                    sewingMachines\n",
      "14       graphicNovels, antiqueJewelry, leatherGoods\n",
      "15                                      concertMerch\n",
      "16                                             books\n",
      "17                                   sportsEquipment\n",
      "18  graphicNovels, campingGear, petSittingDogWalking\n",
      "19                               vintageVinylRecords\n",
      "20                                hikingGear, stamps\n",
      "21            woodworkingCommissions, gamingConsoles\n",
      "22                     horrorMemorabilia, powerTools\n",
      "23         exoticSpices, snowboardingGear, customArt\n",
      "24                    snowboardingGear, vintageLamps\n",
      "25      handmadeRugs, candlesIncense, antiqueJewelry\n",
      "26                         headphones, tattooDesigns\n",
      "27                      videoGames, smartHomeDevices\n",
      "28   bicyclesBikeParts, concertMerch, smallFurniture\n",
      "29                        concertMerch, handmadeSoap\n",
      "30   vintageLamps, jewelryMakingKits, embroideryKits\n",
      "31                                     codingLessons\n",
      "32                        scooterParts, handmadeRugs\n",
      "33                                 bicyclesBikeParts\n",
      "34              musicalInstruments, vintagePostcards\n",
      "35                     vintagePostcards, coffeeBeans\n",
      "36                                    costumeJewelry\n",
      "37                                     codingLessons\n",
      "38                                 dslrCamerasLenses>\n"
     ]
    }
   ],
   "source": [
    "random.seed(10)\n",
    "user = random.randint(0,500)\n",
    "\n",
    "df_all_posts, df_user, df_liked_posts = call_for_data(user)\n",
    "\n",
    "print(f\"all posts: {df_all_posts}\")\n",
    "print(f\"user info: {df_user}\")\n",
    "print(f\"user name: {df_user['name']}\")\n",
    "print(f\"user liked posts: {df_liked_posts.head}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    manga Anime Merch, diy Tools, mechanical Keybo...\n",
      "1    collectible Pins, pet Sitting Dog Walking, vin...\n",
      "2                             custom Toys, baked Goods\n",
      "3    clay Modeling Kits, coding Lessons, tattoo Des...\n",
      "4                 leather Goods, bike Repairs, watches\n",
      "Name: tags, dtype: object\n",
      "0    [manga Anime Merch, diy Tools, mechanical Keyb...\n",
      "1    [collectible Pins, pet Sitting Dog Walking, vi...\n",
      "2                           [custom Toys, baked Goods]\n",
      "3    [clay Modeling Kits, coding Lessons, tattoo De...\n",
      "4               [leather Goods, bike Repairs, watches]\n",
      "Name: split_tags, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Ignore previous comment about not needing to tokenize those tags.\n",
    "# We're going to do that\n",
    "# Then embed the whole of them total.\n",
    "# And also embed the body of the post I guess.\n",
    "# We also need to include goods but we don't have access to goods.\n",
    "# So I guess we'll just end up concatinating goods?\n",
    "\n",
    "df_all_posts['tags'] = df_all_posts['tags'].apply(camel_case_split)\n",
    "print(df_all_posts['tags'].head())\n",
    "df_all_posts['split_tags'] = df_all_posts['tags'].str.split(', ')\n",
    "print(df_all_posts['split_tags'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation of embeddings\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def generated_weighted_embeddings(post):\n",
    "    clean_tags = preprocess_tags(post[\"tags\"])\n",
    "\n",
    "    tags = post['tags']\n",
    "    # profile = post['user_id']\n",
    "    # goods when we get there\n",
    "    # goods = post['goods']\n",
    "    text = post['text']\n",
    "\n",
    "    tag_embedding = model.encode(\" \".join(clean_tags)) if clean_tags else np.zeros(384)\n",
    "    # This is where we would put goods embeddings\n",
    "    # Idk if we want to weigh it by 2.0 but that's something we can play with,\n",
    "    # goods_embedding = model.encode(goods) * 2.0\n",
    "    # profile_embedding = model.encode(profile)if profile else np.zeros(384)\n",
    "    text_embedding = model.encode(text) if text else np.zeros(384)\n",
    "\n",
    "    combined = np.concatenate([\n",
    "        tag_embedding,\n",
    "        # profile_embedding * 0.5,\n",
    "        text_embedding * 0.3\n",
    "    ])\n",
    "\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tags(tags):\n",
    "    if isinstance(tags, str):\n",
    "        tags = camel_case_split(tags)\n",
    "        return [tag.strip() for tag in tags.split(',') if tag.strip()]\n",
    "    elif isinstance(tags, list):\n",
    "        return [camel_case_split(tag) for tag in tags]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where we insert embeddings into the posts\n",
    "# This will change when we move things to postgres.\n",
    "\n",
    "con = sqlite3.connect(\"/home/acequantum/playtime/dummy_data/1_dummy_data.db\")\n",
    "cursor = con.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS post_embeddings (\n",
    "        post_id INTEGER PRIMARY KEY,\n",
    "        embedding BLOB)\"\"\")\n",
    "\n",
    "cursor.execute(\"SELECT id, tags, user_id, text FROM posts\")\n",
    "posts = [\n",
    "    {\"id\": row[0], \"tags\": row[1], \"user_id\": row[2], \"text\": row[3]}\n",
    "    for row in cursor.fetchall()\n",
    "]\n",
    "\n",
    "# Here's the precomputing\n",
    "for post in posts:\n",
    "    embedding = generated_weighted_embeddings(post)\n",
    "    cursor.execute(\n",
    "        \"INSERT OR REPLACE INTO post_embeddings (post_id, embedding) \\\n",
    "        VALUES (?, ?)\",\n",
    "        (post[\"id\"], json.dumps(embedding.tolist()))\n",
    "    )\n",
    "con.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
